{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "329ac3bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋 다운로드 : drive.google.com/file/d/1CPMBmRj-jBDO2ax4CxkBs9iczIFrs8VA/view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d3d5172",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사전학습 모델 다운로드 :drive.google.com/file/d/1YQl7DEbUzSDOBHtB8QOXDc3-6ZGOaUN5/view?usp=sharing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62220782",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chlwo\\anaconda3\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\chlwo\\anaconda3\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG19_Weights.IMAGENET1K_V1`. You can also use `weights=VGG19_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "from torchvision.transforms.functional import to_pil_image\n",
    "import torch\n",
    "import json\n",
    "import model.model as module_arch\n",
    "from base.trainer import Trainer\n",
    "from utils.logger import Logger\n",
    "from utils.util import get_lr_scheduler\n",
    "from base import data_loader as module_data\n",
    "from model import loss as module_loss\n",
    "from model import metric as module_metric\n",
    "from pathlib import Path\n",
    "from utils.util import denormalize\n",
    "from base.data_loader import CustomDataLoader\n",
    "\n",
    "config_path = 'config.json'\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'\n",
    "    \n",
    "with open(config_path) as handle:\n",
    "    config = json.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c89981ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.path.join(config['trainer']['save_dir'], config['name'])\n",
    "\n",
    "train_logger = Logger()\n",
    "\n",
    "data_loader_class = getattr(module_data, config['data_loader']['type'])\n",
    "data_loader = data_loader_class(**config['data_loader']['args'])\n",
    "valid_data_loader = data_loader.split_validation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88b8a4b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_class = getattr(module_arch, config['generator']['type'])\n",
    "generator = generator_class(**config['generator']['args'])\n",
    "\n",
    "discriminator_class = getattr(module_arch, \n",
    "                              config['discriminator']['type'])\n",
    "discriminator = discriminator_class(**config['discriminator']['args'])\n",
    "\n",
    "loss = {k: getattr(module_loss, v) \n",
    "        for k, v in config['loss'].items()}\n",
    "metrics = [getattr(module_metric, met) \n",
    "           for met in config['metrics']]\n",
    "\n",
    "gen_train_params = filter(lambda p: p.requires_grad, \n",
    "                          generator.parameters())\n",
    "dis_train_params = filter(lambda p: p.requires_grad,\n",
    "                          discriminator.parameters())\n",
    "optimizer_class = getattr(torch.optim, config['optimizer']['type'])\n",
    "optimizer = dict()\n",
    "optimizer['generator'] = optimizer_class(gen_train_params,\n",
    "                                         **config['optimizer']['args'])\n",
    "optimizer['discriminator'] = optimizer_class(dis_train_params,\n",
    "                                             **config['optimizer']['args'])\n",
    "\n",
    "lr_scheduler = dict()\n",
    "lr_scheduler['generator'] = get_lr_scheduler(config['lr_scheduler'],\n",
    "                                             optimizer['generator'])\n",
    "lr_scheduler['discriminator'] = get_lr_scheduler(config['lr_scheduler'],\n",
    "                                                 optimizer['discriminator'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e2092693",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/1151 (0%)] generator_loss: 6903.911133 discriminator_loss: 41457.945703\n",
      "Train Epoch: 1 [16/1151 (1%)] generator_loss: 3669.579346 discriminator_loss: 2692.621753\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(config, generator, discriminator, loss, metrics, \n\u001b[0;32m      2\u001b[0m                   optimizer, lr_scheduler, data_loader, train_logger)\n\u001b[1;32m----> 3\u001b[0m trainer\u001b[38;5;241m.\u001b[39mtrain()\n",
      "File \u001b[1;32m~\\Desktop\\DeblurGAN-pytorch-master\\base\\base_trainer.py:83\u001b[0m, in \u001b[0;36mBaseTrainer.train\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     81\u001b[0m not_improved_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     82\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstart_epoch, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepochs \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m---> 83\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_train_epoch(epoch)\n\u001b[0;32m     85\u001b[0m     log \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepoch\u001b[39m\u001b[38;5;124m'\u001b[39m: epoch}\n\u001b[0;32m     86\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m result\u001b[38;5;241m.\u001b[39mitems():\n",
      "File \u001b[1;32m~\\Desktop\\DeblurGAN-pytorch-master\\base\\trainer.py:78\u001b[0m, in \u001b[0;36mTrainer._train_epoch\u001b[1;34m(self, epoch)\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwriter\u001b[38;5;241m.\u001b[39madd_scalar(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwgan_loss_d\u001b[39m\u001b[38;5;124m'\u001b[39m, wgan_loss_d\u001b[38;5;241m.\u001b[39mitem())\n\u001b[0;32m     76\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwriter\u001b[38;5;241m.\u001b[39madd_scalar(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgp_d\u001b[39m\u001b[38;5;124m'\u001b[39m, gp_d\u001b[38;5;241m.\u001b[39mitem())\n\u001b[1;32m---> 78\u001b[0m discriminator_loss_per_update\u001b[38;5;241m.\u001b[39mbackward(retain_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     79\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdiscriminator_optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     80\u001b[0m discriminator_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m discriminator_loss_per_update\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\_tensor.py:492\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    482\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    483\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    484\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    485\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    490\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    491\u001b[0m     )\n\u001b[1;32m--> 492\u001b[0m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mbackward(\n\u001b[0;32m    493\u001b[0m     \u001b[38;5;28mself\u001b[39m, gradient, retain_graph, create_graph, inputs\u001b[38;5;241m=\u001b[39minputs\n\u001b[0;32m    494\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\autograd\\__init__.py:251\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    246\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    248\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    250\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 251\u001b[0m Variable\u001b[38;5;241m.\u001b[39m_execution_engine\u001b[38;5;241m.\u001b[39mrun_backward(  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    252\u001b[0m     tensors,\n\u001b[0;32m    253\u001b[0m     grad_tensors_,\n\u001b[0;32m    254\u001b[0m     retain_graph,\n\u001b[0;32m    255\u001b[0m     create_graph,\n\u001b[0;32m    256\u001b[0m     inputs,\n\u001b[0;32m    257\u001b[0m     allow_unreachable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    258\u001b[0m     accumulate_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    259\u001b[0m )\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer = Trainer(config, generator, discriminator, loss, metrics, \n",
    "                  optimizer, lr_scheduler, data_loader, train_logger)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f7d60a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|####################################################################################| 2/2 [00:00<00:00,  2.82it/s]\n"
     ]
    }
   ],
   "source": [
    "# 디블러링 테스트 코드\n",
    "blurred_path = 'test_img'\n",
    "save_path = 'save'\n",
    "model_path = 'checkpoint/G_latest.pth'\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'\n",
    "\n",
    "    \n",
    "checkpoint = torch.load(model_path)\n",
    "config = checkpoint['config']\n",
    "\n",
    "data_loader = CustomDataLoader(data_dir=blurred_path)\n",
    "    \n",
    "generator_class = getattr(module_arch, config['generator']['type'])\n",
    "generator = generator_class(**config['generator']['args'])\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "generator.to(device)\n",
    "\n",
    "generator.load_state_dict(checkpoint['generator'])\n",
    "generator.eval()\n",
    "\n",
    "Path(save_path).mkdir(exist_ok=True, parents=True) \n",
    "with torch.no_grad():\n",
    "    for batch_idx, sample in enumerate(tqdm(data_loader, ascii=True)):\n",
    "        blurred = sample['blurred'].to(device)\n",
    "        image_name = sample['image_name'][0]\n",
    "\n",
    "        result = generator(blurred)\n",
    "        result = to_pil_image(denormalize(result).squeeze().cpu())\n",
    "\n",
    "        result.save(os.path.join(save_path, 'deblurred_' + image_name))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08505ed4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deblur",
   "language": "python",
   "name": "deblurgan"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
