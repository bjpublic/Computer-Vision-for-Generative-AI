{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "780b72b4",
   "metadata": {
    "id": "780b72b4"
   },
   "outputs": [],
   "source": [
    "# Git설치 링크 : git-scm.com/download/win\n",
    "# Wget 다운로드 링크 : eternallybored.org/misc/wget/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f1f6786",
   "metadata": {
    "id": "0f1f6786"
   },
   "outputs": [],
   "source": [
    "# Facades 데이터셋 다운로드 코드\n",
    "# bash download_pix2pix_dataset.sh facades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac1ff6e",
   "metadata": {
    "id": "fac1ff6e"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import sys\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.utils import save_image\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torch.autograd import Variable\n",
    "from models import *\n",
    "from datasets import *\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c14d54",
   "metadata": {
    "id": "04c14d54"
   },
   "outputs": [],
   "source": [
    "start_epoch, end_epochs = 0, 200\n",
    "dataset_name = 'facades'\n",
    "batch_size = 1\n",
    "learning_rate = 0.0002\n",
    "b1, b2 = 0.5, 0.999\n",
    "img_h, img_w = 256, 256\n",
    "sample_interval = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab5d080b",
   "metadata": {
    "id": "ab5d080b"
   },
   "outputs": [],
   "source": [
    "os.makedirs(\"images/%s\" %dataset_name, exist_ok=True)\n",
    "os.makedirs(\"save/%s\" %dataset_name, exist_ok=True)\n",
    "\n",
    "cuda = True if torch.cuda.is_available() else False\n",
    "\n",
    "criterion_GAN = torch.nn.MSELoss()\n",
    "criterion_pixelwise = torch.nn.L1Loss()\n",
    "\n",
    "lambda_pixel = 100\n",
    "\n",
    "patch = (1, img_h // 2 ** 4, img_w // 2 ** 4)\n",
    "\n",
    "generator = GeneratorUNet()\n",
    "discriminator = Discriminator()\n",
    "\n",
    "if cuda:\n",
    "    generator = generator.cuda()\n",
    "    discriminator = discriminator.cuda()\n",
    "    criterion_GAN.cuda()\n",
    "    criterion_pixelwise.cuda()\n",
    "\n",
    "generator.apply(weights_init_normal)\n",
    "discriminator.apply(weights_init_normal)\n",
    "\n",
    "optimizer_G = torch.optim.Adam(generator.parameters(),\n",
    "                               lr=learning_rate, betas=(b1, b2))\n",
    "optimizer_D = torch.optim.Adam(discriminator.parameters(),\n",
    "                               lr=learning_rate, betas=(b1, b2))\n",
    "\n",
    "transforms_ = [\n",
    "    transforms.Resize((img_h, img_w), Image.BICUBIC),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "]\n",
    "\n",
    "dataloader = DataLoader(\n",
    "    ImageDataset(\"./%s\" % dataset_name, transforms_=transforms_),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=8,\n",
    ")\n",
    "\n",
    "val_dataloader = DataLoader(\n",
    "    ImageDataset(\"./%s\" % dataset_name, transforms_=transforms_, mode=\"val\"),\n",
    "    batch_size=10,\n",
    "    shuffle=True,\n",
    "    num_workers=1,\n",
    ")\n",
    "\n",
    "Tensor = torch.cuda.FloatTensor if cuda else torch.FloatTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e2dd58",
   "metadata": {
    "id": "82e2dd58"
   },
   "outputs": [],
   "source": [
    "def sample_images(batches_done):\n",
    "    imgs = next(iter(val_dataloader))\n",
    "    real_A = Variable(imgs[\"B\"].type(Tensor))\n",
    "    real_B = Variable(imgs[\"A\"].type(Tensor))\n",
    "    fake_B = generator(real_A)\n",
    "    img_sample = torch.cat((real_A.data, fake_B.data, real_B.data), -2)\n",
    "    save_image(img_sample, \"images/%s/%s.png\" % (dataset_name, batches_done), nrow=5, normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec85a77",
   "metadata": {
    "id": "2ec85a77",
    "outputId": "4514324a-9892-4857-c44e-f1c944aae4ad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0/200] [Batch 59/506] [D loss: 0.453430] [G loss: 42.223408, pixel: 0.415385, adv: 0.684910] ETA: 1:10:51.7617031.344002"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 47\u001b[0m\n\u001b[0;32m     37\u001b[0m time_left \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mtimedelta(seconds\u001b[38;5;241m=\u001b[39mbatches_left \u001b[38;5;241m*\u001b[39m (time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m prev_time))\n\u001b[0;32m     38\u001b[0m prev_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m     40\u001b[0m sys\u001b[38;5;241m.\u001b[39mstdout\u001b[38;5;241m.\u001b[39mwrite(\n\u001b[0;32m     41\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\r\u001b[39;00m\u001b[38;5;124m[Epoch \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m] [Batch \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m] [D loss: \u001b[39m\u001b[38;5;132;01m%f\u001b[39;00m\u001b[38;5;124m] [G loss: \u001b[39m\u001b[38;5;132;01m%f\u001b[39;00m\u001b[38;5;124m, pixel: \u001b[39m\u001b[38;5;132;01m%f\u001b[39;00m\u001b[38;5;124m, adv: \u001b[39m\u001b[38;5;132;01m%f\u001b[39;00m\u001b[38;5;124m] ETA: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     42\u001b[0m     \u001b[38;5;241m%\u001b[39m (\n\u001b[0;32m     43\u001b[0m         epoch,\n\u001b[0;32m     44\u001b[0m         end_epochs,\n\u001b[0;32m     45\u001b[0m         i,\n\u001b[0;32m     46\u001b[0m         \u001b[38;5;28mlen\u001b[39m(dataloader),\n\u001b[1;32m---> 47\u001b[0m         loss_D\u001b[38;5;241m.\u001b[39mitem(),\n\u001b[0;32m     48\u001b[0m         loss_G\u001b[38;5;241m.\u001b[39mitem(),\n\u001b[0;32m     49\u001b[0m         loss_pixel\u001b[38;5;241m.\u001b[39mitem(),\n\u001b[0;32m     50\u001b[0m         loss_GAN\u001b[38;5;241m.\u001b[39mitem(),\n\u001b[0;32m     51\u001b[0m         time_left,\n\u001b[0;32m     52\u001b[0m     )\n\u001b[0;32m     53\u001b[0m )\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batches_done \u001b[38;5;241m%\u001b[39m sample_interval \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m     56\u001b[0m     sample_images(batches_done)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "for epoch in range(start_epoch, end_epochs):\n",
    "    for i, batch in enumerate(dataloader):\n",
    "        real_A = Variable(batch[\"B\"].type(Tensor))\n",
    "        real_B = Variable(batch[\"A\"].type(Tensor))\n",
    "\n",
    "        valid = Variable(Tensor(np.ones((real_A.size(0), *patch))), requires_grad=False)\n",
    "        fake = Variable(Tensor(np.zeros((real_A.size(0), *patch))), requires_grad=False)\n",
    "\n",
    "        optimizer_G.zero_grad()\n",
    "\n",
    "        fake_B = generator(real_A)\n",
    "        pred_fake = discriminator(fake_B, real_A)\n",
    "        loss_GAN = criterion_GAN(pred_fake, valid)\n",
    "        loss_pixel = criterion_pixelwise(fake_B, real_B)\n",
    "\n",
    "        loss_G = loss_GAN + lambda_pixel * loss_pixel\n",
    "        loss_G.backward()\n",
    "\n",
    "        optimizer_G.step()\n",
    "\n",
    "\n",
    "        optimizer_D.zero_grad()\n",
    "\n",
    "        pred_real = discriminator(real_B, real_A)\n",
    "        loss_real = criterion_GAN(pred_real, valid)\n",
    "        pred_fake = discriminator(fake_B.detach(), real_A)\n",
    "        loss_fake = criterion_GAN(pred_fake, fake)\n",
    "\n",
    "        loss_D = 0.5 * (loss_real + loss_fake)\n",
    "        loss_D.backward()\n",
    "        optimizer_D.step()\n",
    "\n",
    "        batches_done = epoch * len(dataloader) + i\n",
    "\n",
    "        sys.stdout.write(\n",
    "            \"\\r[Epoch %d/%d] [Batch %d/%d] [D loss: %f] [G loss: %f, pixel: %f, adv: %f]\"\n",
    "            % (\n",
    "                epoch,\n",
    "                end_epochs,\n",
    "                i,\n",
    "                len(dataloader),\n",
    "                loss_D.item(),\n",
    "                loss_G.item(),\n",
    "                loss_pixel.item(),\n",
    "                loss_GAN.item(),\n",
    "            )\n",
    "        )\n",
    "\n",
    "        if batches_done % sample_interval == 0:\n",
    "            sample_images(batches_done)\n",
    "\n",
    "    if epoch == (end_epoch-1):\n",
    "        torch.save(generator.state_dict(), \"save/%s/generator_%d.pth\" % (dataset_name, epoch))\n",
    "        torch.save(discriminator.state_dict(), \"save/%s/discriminator_%d.pth\" % (dataset_name, epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c44e51",
   "metadata": {
    "id": "82c44e51"
   },
   "outputs": [],
   "source": [
    "generator.load_state_dict(torch.load(\"save/%s/generator_199.pth\"\n",
    "                                         %(dataset_name)))\n",
    "discriminator.load_state_dict(torch.load(\"save/%s/discriminator_199.pth\"\n",
    "                                             %(dataset_name)))\n",
    "imgs = next(iter(val_dataloader))\n",
    "real_A = Variable(imgs[\"B\"].type(Tensor))\n",
    "fake_B = generator(real_A)\n",
    "img_sample = torch.cat((real_A.data, fake_B.data), -2)\n",
    "save_image(img_sample, \"images/%s/generation.png\" % (dataset_name), nrow=5, normalize=True)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [
    {
     "file_id": "1-3rPIz3TX1_R_JOUsXeqjw7l5DVJh-VF",
     "timestamp": 1707912016569
    }
   ]
  },
  "kernelspec": {
   "display_name": "pix2pix",
   "language": "python",
   "name": "pix2pix"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
