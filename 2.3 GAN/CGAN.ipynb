{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e1cfeb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import math\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.utils import save_image\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62fa598d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on GPU \n",
      "CUDA is available\n"
     ]
    }
   ],
   "source": [
    "epochs, batch_size  = 100, 64\n",
    "lr, b1, b2 = 2e-4, 0.5, 0.999\n",
    "latent_dim = 100\n",
    "img_size = 32\n",
    "channels = 1\n",
    "n_classes = 10\n",
    "img_shape = (channels, img_size, img_size)\n",
    "if torch.cuda.is_available(): \n",
    "    print(\"Train on GPU \\nCUDA is available\")\n",
    "    cuda = True \n",
    "else:\n",
    "    print(\"Train on the CPU \\nCUDA is not available\")\n",
    "    cuda = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce822a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"data/mnist\", exist_ok=True)\n",
    "dataloader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST(\n",
    "        \"data/mnist\",\n",
    "        train=True,\n",
    "        download=True,\n",
    "        transform=transforms.Compose(\n",
    "            [transforms.Resize(img_size), transforms.ToTensor(), transforms.Normalize([0.5], [0.5])]\n",
    "        ),\n",
    "    ),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d44564b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        self.label_emb = nn.Embedding(n_classes, n_classes)\n",
    "        \n",
    "        def block(in_feat, out_feat, normalize=True):\n",
    "            layers = [nn.Linear(in_feat, out_feat)]\n",
    "            if normalize:\n",
    "                layers.append(nn.BatchNorm1d(out_feat, 0.8))\n",
    "            layers.append(nn.LeakyReLU(0.2, inplace=True))\n",
    "            return layers\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            *block(latent_dim + n_classes, 128, normalize=False),\n",
    "            *block(128, 256),\n",
    "            *block(256, 512),\n",
    "            *block(512, 1024),\n",
    "            nn.Linear(1024, int(np.prod(img_shape))),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, noise, labels):\n",
    "        input_z = torch.cat((self.label_emb(labels), noise), -1)\n",
    "        img = self.model(input_z)\n",
    "        img = img.view(img.size(0), *img_shape)\n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ed1a39d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.label_embedding = nn.Embedding(n_classes, n_classes)\n",
    "        \n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(n_classes + int(np.prod(img_shape)), 512),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(512, 1),\n",
    "        )\n",
    "\n",
    "    def forward(self, img, labels):\n",
    "        input_x = torch.cat((img.view(img.size(0), -1), self.label_embedding(labels)), -1)\n",
    "        pred = self.model(input_x)\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c60a13dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "G = Generator()\n",
    "D = Discriminator()\n",
    "adversarial_loss = torch.nn.MSELoss()\n",
    "\n",
    "if cuda:\n",
    "    G.cuda()\n",
    "    D.cuda()\n",
    "    adversarial_loss.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2506c849",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_save(n_row, epoch):\n",
    "    z = Variable(FloatTensor(np.random.normal\n",
    "                             (0, 1, (n_row ** 2, latent_dim))))\n",
    "    labels = np.array([num for _ in range(n_row) \n",
    "                       for num in range(n_row)])\n",
    "    labels = Variable(LongTensor(labels))\n",
    "    img_g = G(z, labels)\n",
    "    save_image(img_g.data, \"CGAN_results/%d.png\" \n",
    "               %epoch, nrow=n_row, normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4ec2a10d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chlwo\\AppData\\Local\\Temp\\ipykernel_20692\\1542768952.py:6: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at ..\\torch\\csrc\\tensor\\python_tensor.cpp:85.)\n",
      "  real = Variable(FloatTensor(batch_size, 1).fill_(1.0),requires_grad=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0/100] [D loss: 0.136978] [G loss: 0.345224]\n",
      "[Epoch 1/100] [D loss: 0.076319] [G loss: 0.675061]\n",
      "[Epoch 2/100] [D loss: 0.096402] [G loss: 0.581036]\n",
      "[Epoch 3/100] [D loss: 0.074213] [G loss: 0.718553]\n",
      "[Epoch 4/100] [D loss: 0.148068] [G loss: 0.495342]\n",
      "[Epoch 5/100] [D loss: 0.153791] [G loss: 0.514250]\n",
      "[Epoch 6/100] [D loss: 0.231861] [G loss: 0.176790]\n",
      "[Epoch 7/100] [D loss: 0.146515] [G loss: 0.541679]\n",
      "[Epoch 8/100] [D loss: 0.180008] [G loss: 0.426851]\n",
      "[Epoch 9/100] [D loss: 0.210126] [G loss: 0.389083]\n",
      "[Epoch 10/100] [D loss: 0.176833] [G loss: 0.459842]\n",
      "[Epoch 11/100] [D loss: 0.196350] [G loss: 0.651260]\n",
      "[Epoch 12/100] [D loss: 0.184078] [G loss: 0.458031]\n",
      "[Epoch 13/100] [D loss: 0.228992] [G loss: 0.258839]\n",
      "[Epoch 14/100] [D loss: 0.189214] [G loss: 0.353010]\n",
      "[Epoch 15/100] [D loss: 0.246752] [G loss: 0.247599]\n",
      "[Epoch 16/100] [D loss: 0.222593] [G loss: 0.341538]\n",
      "[Epoch 17/100] [D loss: 0.210312] [G loss: 0.235605]\n",
      "[Epoch 18/100] [D loss: 0.241484] [G loss: 0.291656]\n",
      "[Epoch 19/100] [D loss: 0.221683] [G loss: 0.364844]\n",
      "[Epoch 20/100] [D loss: 0.208965] [G loss: 0.297596]\n",
      "[Epoch 21/100] [D loss: 0.187725] [G loss: 0.322450]\n",
      "[Epoch 22/100] [D loss: 0.196918] [G loss: 0.416479]\n",
      "[Epoch 23/100] [D loss: 0.205429] [G loss: 0.304532]\n",
      "[Epoch 24/100] [D loss: 0.177098] [G loss: 0.431218]\n",
      "[Epoch 25/100] [D loss: 0.230848] [G loss: 0.378688]\n",
      "[Epoch 26/100] [D loss: 0.216455] [G loss: 0.315970]\n",
      "[Epoch 27/100] [D loss: 0.206299] [G loss: 0.376087]\n",
      "[Epoch 28/100] [D loss: 0.222022] [G loss: 0.314885]\n",
      "[Epoch 29/100] [D loss: 0.193411] [G loss: 0.463371]\n",
      "[Epoch 30/100] [D loss: 0.179346] [G loss: 0.360428]\n",
      "[Epoch 31/100] [D loss: 0.210559] [G loss: 0.389862]\n",
      "[Epoch 32/100] [D loss: 0.202495] [G loss: 0.321690]\n",
      "[Epoch 33/100] [D loss: 0.175838] [G loss: 0.417522]\n",
      "[Epoch 34/100] [D loss: 0.201410] [G loss: 0.456188]\n",
      "[Epoch 35/100] [D loss: 0.148426] [G loss: 0.508886]\n",
      "[Epoch 36/100] [D loss: 0.196306] [G loss: 0.368823]\n",
      "[Epoch 37/100] [D loss: 0.166339] [G loss: 0.449166]\n",
      "[Epoch 38/100] [D loss: 0.189094] [G loss: 0.538015]\n",
      "[Epoch 39/100] [D loss: 0.189381] [G loss: 0.502040]\n",
      "[Epoch 40/100] [D loss: 0.164365] [G loss: 0.420397]\n",
      "[Epoch 41/100] [D loss: 0.131819] [G loss: 0.527142]\n",
      "[Epoch 42/100] [D loss: 0.174301] [G loss: 0.347195]\n",
      "[Epoch 43/100] [D loss: 0.177355] [G loss: 0.477416]\n",
      "[Epoch 44/100] [D loss: 0.171093] [G loss: 0.331560]\n",
      "[Epoch 45/100] [D loss: 0.224546] [G loss: 0.294316]\n",
      "[Epoch 46/100] [D loss: 0.205378] [G loss: 0.445817]\n",
      "[Epoch 47/100] [D loss: 0.171332] [G loss: 0.702279]\n",
      "[Epoch 48/100] [D loss: 0.157642] [G loss: 0.515496]\n",
      "[Epoch 49/100] [D loss: 0.146945] [G loss: 0.725286]\n",
      "[Epoch 50/100] [D loss: 0.183984] [G loss: 0.784965]\n",
      "[Epoch 51/100] [D loss: 0.138869] [G loss: 0.423955]\n",
      "[Epoch 52/100] [D loss: 0.167770] [G loss: 0.725518]\n",
      "[Epoch 53/100] [D loss: 0.146504] [G loss: 0.511003]\n",
      "[Epoch 54/100] [D loss: 0.171315] [G loss: 0.434899]\n",
      "[Epoch 55/100] [D loss: 0.149954] [G loss: 0.426780]\n",
      "[Epoch 56/100] [D loss: 0.197121] [G loss: 0.305580]\n",
      "[Epoch 57/100] [D loss: 0.171629] [G loss: 0.504287]\n",
      "[Epoch 58/100] [D loss: 0.136997] [G loss: 0.404519]\n",
      "[Epoch 59/100] [D loss: 0.145197] [G loss: 0.477898]\n",
      "[Epoch 60/100] [D loss: 0.215468] [G loss: 0.237191]\n",
      "[Epoch 61/100] [D loss: 0.211727] [G loss: 0.256244]\n",
      "[Epoch 62/100] [D loss: 0.141943] [G loss: 0.627148]\n",
      "[Epoch 63/100] [D loss: 0.129591] [G loss: 0.479240]\n",
      "[Epoch 64/100] [D loss: 0.177495] [G loss: 0.674355]\n",
      "[Epoch 65/100] [D loss: 0.135759] [G loss: 0.403373]\n",
      "[Epoch 66/100] [D loss: 0.174839] [G loss: 0.322359]\n",
      "[Epoch 67/100] [D loss: 0.140097] [G loss: 0.463575]\n",
      "[Epoch 68/100] [D loss: 0.150050] [G loss: 0.461033]\n",
      "[Epoch 69/100] [D loss: 0.268135] [G loss: 0.163280]\n",
      "[Epoch 70/100] [D loss: 0.146306] [G loss: 0.851246]\n",
      "[Epoch 71/100] [D loss: 0.243936] [G loss: 0.154186]\n",
      "[Epoch 72/100] [D loss: 0.119849] [G loss: 0.692080]\n",
      "[Epoch 73/100] [D loss: 0.136063] [G loss: 0.678061]\n",
      "[Epoch 74/100] [D loss: 0.172696] [G loss: 0.989895]\n",
      "[Epoch 75/100] [D loss: 0.141107] [G loss: 0.904991]\n",
      "[Epoch 76/100] [D loss: 0.107864] [G loss: 0.542702]\n",
      "[Epoch 77/100] [D loss: 0.161193] [G loss: 0.881654]\n",
      "[Epoch 78/100] [D loss: 0.167568] [G loss: 0.552470]\n",
      "[Epoch 79/100] [D loss: 0.101837] [G loss: 0.639906]\n",
      "[Epoch 80/100] [D loss: 0.191996] [G loss: 0.268086]\n",
      "[Epoch 81/100] [D loss: 0.317072] [G loss: 0.124305]\n",
      "[Epoch 82/100] [D loss: 0.078856] [G loss: 0.721972]\n",
      "[Epoch 83/100] [D loss: 0.128924] [G loss: 0.640429]\n",
      "[Epoch 84/100] [D loss: 0.153984] [G loss: 0.329533]\n",
      "[Epoch 85/100] [D loss: 0.126840] [G loss: 0.660795]\n",
      "[Epoch 86/100] [D loss: 0.117048] [G loss: 0.487874]\n",
      "[Epoch 87/100] [D loss: 0.100693] [G loss: 0.510008]\n",
      "[Epoch 88/100] [D loss: 0.128929] [G loss: 0.693208]\n",
      "[Epoch 89/100] [D loss: 0.086312] [G loss: 0.706330]\n",
      "[Epoch 90/100] [D loss: 0.072990] [G loss: 0.678323]\n",
      "[Epoch 91/100] [D loss: 0.123850] [G loss: 0.432507]\n",
      "[Epoch 92/100] [D loss: 0.140997] [G loss: 0.808707]\n",
      "[Epoch 93/100] [D loss: 0.111563] [G loss: 0.823180]\n",
      "[Epoch 94/100] [D loss: 0.254643] [G loss: 0.922541]\n",
      "[Epoch 95/100] [D loss: 0.383143] [G loss: 0.039892]\n",
      "[Epoch 96/100] [D loss: 0.061737] [G loss: 0.620024]\n",
      "[Epoch 97/100] [D loss: 0.128982] [G loss: 0.736031]\n",
      "[Epoch 98/100] [D loss: 0.174431] [G loss: 0.983091]\n",
      "[Epoch 99/100] [D loss: 0.078802] [G loss: 0.937735]\n"
     ]
    }
   ],
   "source": [
    "optimizer_G = torch.optim.Adam(G.parameters(),lr=lr, betas=(b1, b2))\n",
    "optimizer_D = torch.optim.Adam(D.parameters(),lr=lr, betas=(b1, b2))\n",
    "\n",
    "FloatTensor = torch.cuda.FloatTensor if cuda else torch.FloatTensor\n",
    "LongTensor = torch.cuda.LongTensor if cuda else torch.LongTensor\n",
    "\n",
    "os.makedirs(\"CGAN_results\", exist_ok=True)\n",
    "for epoch in range(epochs):\n",
    "    for i, (imgs, labels) in enumerate(dataloader):\n",
    "\n",
    "        batch_size = imgs.shape[0]\n",
    "\n",
    "        real = Variable(FloatTensor(batch_size, 1).fill_(1.0),requires_grad=False)\n",
    "        fake = Variable(FloatTensor(batch_size, 1).fill_(0.0),requires_grad=False)\n",
    "        real_imgs = Variable(imgs.type(FloatTensor))\n",
    "        labels = Variable(labels.type(LongTensor))\n",
    "        \n",
    "        ## Train Generator ##\n",
    "        optimizer_G.zero_grad()\n",
    "        z = Variable(FloatTensor(np.random.normal\n",
    "                                 (0, 1, (batch_size, latent_dim))))\n",
    "        gen_labels = Variable(LongTensor(np.random.randint(0, n_classes, batch_size)))\n",
    "        gen_imgs = G(z, gen_labels)\n",
    "        fake_pred = D(gen_imgs, gen_labels)\n",
    "        g_loss = adversarial_loss(fake_pred, real)\n",
    "        g_loss.backward()\n",
    "        optimizer_G.step()\n",
    "        \n",
    "        ## Train Discriminator ##\n",
    "        optimizer_D.zero_grad()\n",
    "        real_pred = D(real_imgs, labels)\n",
    "        d_real_loss = adversarial_loss(real_pred, real)\n",
    "        fake_pred = D(gen_imgs.detach(), gen_labels)\n",
    "        d_fake_loss = adversarial_loss(fake_pred, fake)\n",
    "        d_loss = (d_real_loss + d_fake_loss) / 2\n",
    "        d_loss.backward()\n",
    "        optimizer_D.step()\n",
    "\n",
    "    print(\n",
    "        \"[Epoch %d/%d] [D loss: %f] [G loss: %f]\"\n",
    "        % (epoch, epochs, d_loss.item(), g_loss.item())\n",
    "    )\n",
    "\n",
    "    sample_save(n_row=10, epoch=epoch+1)\n",
    "torch.save(G.state_dict(), './Generator.pth')\n",
    "torch.save(D.state_dict(), './Discriminator.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vision2",
   "language": "python",
   "name": "vision_2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
